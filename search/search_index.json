{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Build the right thing, and build the thing right. \u00b6 This site contains a tiny sample of my notes and experience I've gathered over my professional career as a software developer and DevOps engineer. Find me on LinkedIn . It's purpose for creation was for me to learn about mkdocs and TravisCI over a weekend. Summary mkdocs: great, travisci: not-so-much. Andrew Garner Site built with MKDocs and Travic-CI","title":"Home"},{"location":"#build-the-right-thing-and-build-the-thing-right","text":"This site contains a tiny sample of my notes and experience I've gathered over my professional career as a software developer and DevOps engineer. Find me on LinkedIn . It's purpose for creation was for me to learn about mkdocs and TravisCI over a weekend. Summary mkdocs: great, travisci: not-so-much. Andrew Garner Site built with MKDocs and Travic-CI","title":"Build the right thing, and build the thing right."},{"location":"ansible/collections/","text":"Collections \u00b6 Documenting Collections \u00b6 ansible-docs displays documentation from docstrings in the python file which implements the Ansible Module or Plugin. https://docs.ansible.com/ansible/latest/dev_guide/developing_modules_documenting.html describes the expected format for the docstrings. While the documentation states \"...Any parsing errors will be obvious - you can view details by adding -vvv to the command.\", my experience differs. The guidelines require adding # -*- coding: utf-8 -*- which I'm not a fan of as Python3 sets this by default, however if you are open-sourcing a Collection it must still be compatible with Python2. https://realpython.com/python-encodings-guide/#python-3-all-in-on-unicode Testing module documentation \u00b6 See https://docs.ansible.com/ansible/latest/dev_guide/testing_documentation.html#testing-module-documentation Modules and Plugins \u00b6 A Module runs on the remote system, a Plugin runs on the Ansible Control node. See https://docs.ansible.com/ansible/latest/dev_guide/developing_locally.html#modules-and-plugins-what-s-the-difference","title":"Collections"},{"location":"ansible/collections/#collections","text":"","title":"Collections"},{"location":"ansible/collections/#documenting-collections","text":"ansible-docs displays documentation from docstrings in the python file which implements the Ansible Module or Plugin. https://docs.ansible.com/ansible/latest/dev_guide/developing_modules_documenting.html describes the expected format for the docstrings. While the documentation states \"...Any parsing errors will be obvious - you can view details by adding -vvv to the command.\", my experience differs. The guidelines require adding # -*- coding: utf-8 -*- which I'm not a fan of as Python3 sets this by default, however if you are open-sourcing a Collection it must still be compatible with Python2. https://realpython.com/python-encodings-guide/#python-3-all-in-on-unicode","title":"Documenting Collections"},{"location":"ansible/collections/#testing-module-documentation","text":"See https://docs.ansible.com/ansible/latest/dev_guide/testing_documentation.html#testing-module-documentation","title":"Testing module documentation"},{"location":"ansible/collections/#modules-and-plugins","text":"A Module runs on the remote system, a Plugin runs on the Ansible Control node. See https://docs.ansible.com/ansible/latest/dev_guide/developing_locally.html#modules-and-plugins-what-s-the-difference","title":"Modules and Plugins"},{"location":"ansible/filters/","text":"Filters \u00b6 Use-case \u00b6 This was developed to perform post-deployment verification against a RESTful service. The tomcat app startup script would always return before the application was ready to serve traffic and also there is a belt-and-braces check against a version endpoint to check that the url is serving the version on the application we believe should have just been deployed. The uri module handles getting what is unfortunately in this case html, then we need to extract the application version from the content. Cue Ansible Filters regex_search \u00b6 regex_search can perform the search and return the matched string. I won't share the whole html here, but note there are multiple versions in the html with no unique IDs on any of the elements. So how to extract just the application version? Although in python we can get this using a single regex and a match group, regex_search cannot return just the match group, only the whole match. < li > application version : 7.12.0-SNAPSHOT </ li > We can do this in two simple steps using regex_search, the first filter matches the project version and sets that as a fact which we can search again and this time there is only one version number in the string to be searched and extracting the version number is now easy with a second regex. - name : extract version element from response set_fact : deployed_application_version_element : \"{{ response | regex_search('application version : ([\\\\w\\\\.\\\\-]+)') }}\" - name : extract version string from element set_fact : deployed_application_version : \"{{ deployed_application_version_element | regex_search('(\\\\d+.*$)') }}\" - name : check facts debug : var : deployed_application_version Note Ansible (2.6) does not support having both facts set in a single task. The following code prodeces the error below because the first fact is not set when the second fact tries to reference it. - name : extract versions from response set_fact : deployed_application_version_element : \"{{ response | regex_search('application version : ([\\\\w\\\\.\\\\-]+)') }}\" deployed_application_version : \"{{ deployed_application_version_element | regex_search('(\\\\d+.*$)') }}\" TASK [ extract versions from response ] ***************************************************************************************** fatal: [ localhost ] : FAILED! = > { \"msg\" : \"Unexpected templating type error occurred on ({{ deployed_application_version_element | regex_search('(\\\\\\\\d+.* $ )') }}): expected string or buffer\" } The error is clearer if we drop the regex_search filter from the second fact, although as always we must read the Ansible error message carefully and fully. - name : extract versions from response set_fact : deployed_application_version_element : \"{{ response | regex_search('application version : ([\\\\w\\\\.\\\\-]+)') }}\" deployed_application_version : \"{{ deployed_application_version_element }}\" ```bash TASK [extract versions from response] ***************************************************************************************** fatal: [localhost]: FAILED! => {\"msg\": \"The task includes an option with an undefined variable. The error was: 'deployed_project_version_match' is undefined\\n\\nThe error appears to have been in '/Users/agar/code/agarthetiger/ansible/check-version.yml': line 9, column 7, but may\\nbe elsewhere in the file depending on the exact syntax problem.\\n\\nThe offending line appears to be:\\n\\n\\n - name: extract versions from response\\n ^ here\\n\"} regex_replace \u00b6 It would be elegant to get this in one step and we can do that with regex_replace, where the replacement string can reference match groups. We need to modify the original regex slightly so the entire string is matched, in order for just the replacement match group to become the returned string. Lets break the regex down. The leading ^.* and trailing .*?$ ensure that the whole string is matched and replaced by the match group application version : matches the text in the list html element for the version we're interested in ([\\w\\.\\-]) matches any word character (letters, numbers and underscore) plus dot and hyphen and the round brackets around this expression mark it as the first (and only) match group. - name : extract application version from response set_fact : deployed_application_version : \"{{ response | regex_replace('^.*application version : ([\\\\w\\\\.\\\\-]+).*?$', '\\\\1') }}\" Online tools like pythex.org can be useful for quickly testing regular expressions. Danger Be very careful about what you paste into online tools like this. Always triple check that you are never sharing anything sensitive and if in doubt test a rexeg locally, even if it is more cumbersome. Security is never worth risking for speed.","title":"Filters"},{"location":"ansible/filters/#filters","text":"","title":"Filters"},{"location":"ansible/filters/#use-case","text":"This was developed to perform post-deployment verification against a RESTful service. The tomcat app startup script would always return before the application was ready to serve traffic and also there is a belt-and-braces check against a version endpoint to check that the url is serving the version on the application we believe should have just been deployed. The uri module handles getting what is unfortunately in this case html, then we need to extract the application version from the content. Cue Ansible Filters","title":"Use-case"},{"location":"ansible/filters/#regex_search","text":"regex_search can perform the search and return the matched string. I won't share the whole html here, but note there are multiple versions in the html with no unique IDs on any of the elements. So how to extract just the application version? Although in python we can get this using a single regex and a match group, regex_search cannot return just the match group, only the whole match. < li > application version : 7.12.0-SNAPSHOT </ li > We can do this in two simple steps using regex_search, the first filter matches the project version and sets that as a fact which we can search again and this time there is only one version number in the string to be searched and extracting the version number is now easy with a second regex. - name : extract version element from response set_fact : deployed_application_version_element : \"{{ response | regex_search('application version : ([\\\\w\\\\.\\\\-]+)') }}\" - name : extract version string from element set_fact : deployed_application_version : \"{{ deployed_application_version_element | regex_search('(\\\\d+.*$)') }}\" - name : check facts debug : var : deployed_application_version Note Ansible (2.6) does not support having both facts set in a single task. The following code prodeces the error below because the first fact is not set when the second fact tries to reference it. - name : extract versions from response set_fact : deployed_application_version_element : \"{{ response | regex_search('application version : ([\\\\w\\\\.\\\\-]+)') }}\" deployed_application_version : \"{{ deployed_application_version_element | regex_search('(\\\\d+.*$)') }}\" TASK [ extract versions from response ] ***************************************************************************************** fatal: [ localhost ] : FAILED! = > { \"msg\" : \"Unexpected templating type error occurred on ({{ deployed_application_version_element | regex_search('(\\\\\\\\d+.* $ )') }}): expected string or buffer\" } The error is clearer if we drop the regex_search filter from the second fact, although as always we must read the Ansible error message carefully and fully. - name : extract versions from response set_fact : deployed_application_version_element : \"{{ response | regex_search('application version : ([\\\\w\\\\.\\\\-]+)') }}\" deployed_application_version : \"{{ deployed_application_version_element }}\" ```bash TASK [extract versions from response] ***************************************************************************************** fatal: [localhost]: FAILED! => {\"msg\": \"The task includes an option with an undefined variable. The error was: 'deployed_project_version_match' is undefined\\n\\nThe error appears to have been in '/Users/agar/code/agarthetiger/ansible/check-version.yml': line 9, column 7, but may\\nbe elsewhere in the file depending on the exact syntax problem.\\n\\nThe offending line appears to be:\\n\\n\\n - name: extract versions from response\\n ^ here\\n\"}","title":"regex_search"},{"location":"ansible/filters/#regex_replace","text":"It would be elegant to get this in one step and we can do that with regex_replace, where the replacement string can reference match groups. We need to modify the original regex slightly so the entire string is matched, in order for just the replacement match group to become the returned string. Lets break the regex down. The leading ^.* and trailing .*?$ ensure that the whole string is matched and replaced by the match group application version : matches the text in the list html element for the version we're interested in ([\\w\\.\\-]) matches any word character (letters, numbers and underscore) plus dot and hyphen and the round brackets around this expression mark it as the first (and only) match group. - name : extract application version from response set_fact : deployed_application_version : \"{{ response | regex_replace('^.*application version : ([\\\\w\\\\.\\\\-]+).*?$', '\\\\1') }}\" Online tools like pythex.org can be useful for quickly testing regular expressions. Danger Be very careful about what you paste into online tools like this. Always triple check that you are never sharing anything sensitive and if in doubt test a rexeg locally, even if it is more cumbersome. Security is never worth risking for speed.","title":"regex_replace"},{"location":"ansible/inventory-plugins/","text":"Inventory Plugins \u00b6 All inventory plugins use a config file. Ini or Yaml inventory files are still configuration files, they just happen to contain all the hostnames and ip addresses for the ini and yaml plugins directly. Dynamic inventory plugins also need a config file, they all have a \"plugin:\" key which has to match the inventory filename. It is common for dynamic inventory plugins to have configuration in the contif file (which can be called anything) and for credentials to be read from environment variables. Use ansible-inventory -i <config>.yml --list --yaml to debug the inventory generated by a dynamic inventory script. Note that the --export flag can significantly change the inventory and even exclude variables which would otherwise be included in the inventory. For Collections, the [defaults] INVENTORY_PLUGINS key needs to be configured to specify the path to the folder where the inventory plugin .py file is located. I've not been able to get this working by just specifying the COLLECTIONS_PATH and inventory namespace.","title":"Inventory Plugins"},{"location":"ansible/inventory-plugins/#inventory-plugins","text":"All inventory plugins use a config file. Ini or Yaml inventory files are still configuration files, they just happen to contain all the hostnames and ip addresses for the ini and yaml plugins directly. Dynamic inventory plugins also need a config file, they all have a \"plugin:\" key which has to match the inventory filename. It is common for dynamic inventory plugins to have configuration in the contif file (which can be called anything) and for credentials to be read from environment variables. Use ansible-inventory -i <config>.yml --list --yaml to debug the inventory generated by a dynamic inventory script. Note that the --export flag can significantly change the inventory and even exclude variables which would otherwise be included in the inventory. For Collections, the [defaults] INVENTORY_PLUGINS key needs to be configured to specify the path to the folder where the inventory plugin .py file is located. I've not been able to get this working by just specifying the COLLECTIONS_PATH and inventory namespace.","title":"Inventory Plugins"},{"location":"ansible/local-actions/","text":"Local actions \u00b6 Single module \u00b6 ansible all -m setup -i 192.168.0.11, ansible all execute ansible against host group 'all' -m setup run the setup module to gather information about the hosts -i 192.168.0.11, inline host list, must be comma-separated list of hosts so add training comma for a single host. See Examples on the Ansible Setup module documentation. Local actions \u00b6 If you want to run a playbook and always do things locally, execute the playbook using --connection=local on the command line or connection : local on the play. This instructs ansible not to establish an SSH connection. This is useful if local loobpack is disabled eg. due to firewall rules or security groups. To run a playbook which uses - hosts: all or similar, pass an inventory with just localhost or 127.0.0.1 and connection=local ansible-playbook -i 127.0.0.1, --connection=local myplaybook.yaml Alternatively, within a playbook with tasks to be executed remotely, include a section with - hosts: 127.0.0.1 connection: local More alternatives include using the local_action module which is a shorthand syntax for the delegate_to : 127.0 . 0.1 option. Combine these with run_once : true to ensure things running locally only happen once if that's what you want (like downloading a file once to then use Ansible to push the file to multiple hosts). See Ansible documentation on Delegation This is useful to switch to running selected tasks locally in the middle of a role execution for example, where you cannot add hosts: directives to switch between local and remote execution. - hosts : all gather_facts : false tasks : - name : ensure required parameters have been set fail : msg=\"Variable '{{ item }}' is not defined\" when : item not in vars with_items : - public_key_file - host_user_id run_once : true - name : locate public key file local_action : module : stat path : \"{{ public_key_file }}\" register : keyFile run_once : true Localhost and non-SSH connections \u00b6 ansible_connection=local can be used in the inventory or on the command line to specify how Ansible will connect to the target host. In the case of local actions you can use ansible_connection=local as an inventory parameter with localhost to execute something locally even if you don't have a local loopback connection. The equivalent in a playbook is connection : local . Note localhost will be recognised by Ansible as a valid host if the /etc/hosts file has an entry for 127.0.0.1 localhost or if localhost 127.0.0.1 ansible_connection=local is specified in the inventory, otherwise use 127.0.0.1.","title":"Local actions"},{"location":"ansible/local-actions/#local-actions","text":"","title":"Local actions"},{"location":"ansible/local-actions/#single-module","text":"ansible all -m setup -i 192.168.0.11, ansible all execute ansible against host group 'all' -m setup run the setup module to gather information about the hosts -i 192.168.0.11, inline host list, must be comma-separated list of hosts so add training comma for a single host. See Examples on the Ansible Setup module documentation.","title":"Single module"},{"location":"ansible/local-actions/#local-actions_1","text":"If you want to run a playbook and always do things locally, execute the playbook using --connection=local on the command line or connection : local on the play. This instructs ansible not to establish an SSH connection. This is useful if local loobpack is disabled eg. due to firewall rules or security groups. To run a playbook which uses - hosts: all or similar, pass an inventory with just localhost or 127.0.0.1 and connection=local ansible-playbook -i 127.0.0.1, --connection=local myplaybook.yaml Alternatively, within a playbook with tasks to be executed remotely, include a section with - hosts: 127.0.0.1 connection: local More alternatives include using the local_action module which is a shorthand syntax for the delegate_to : 127.0 . 0.1 option. Combine these with run_once : true to ensure things running locally only happen once if that's what you want (like downloading a file once to then use Ansible to push the file to multiple hosts). See Ansible documentation on Delegation This is useful to switch to running selected tasks locally in the middle of a role execution for example, where you cannot add hosts: directives to switch between local and remote execution. - hosts : all gather_facts : false tasks : - name : ensure required parameters have been set fail : msg=\"Variable '{{ item }}' is not defined\" when : item not in vars with_items : - public_key_file - host_user_id run_once : true - name : locate public key file local_action : module : stat path : \"{{ public_key_file }}\" register : keyFile run_once : true","title":"Local actions"},{"location":"ansible/local-actions/#localhost-and-non-ssh-connections","text":"ansible_connection=local can be used in the inventory or on the command line to specify how Ansible will connect to the target host. In the case of local actions you can use ansible_connection=local as an inventory parameter with localhost to execute something locally even if you don't have a local loopback connection. The equivalent in a playbook is connection : local . Note localhost will be recognised by Ansible as a valid host if the /etc/hosts file has an entry for 127.0.0.1 localhost or if localhost 127.0.0.1 ansible_connection=local is specified in the inventory, otherwise use 127.0.0.1.","title":"Localhost and non-SSH connections"},{"location":"ansible/playbooks/","text":"Playbooks \u00b6 Conditional checks \u00b6 Conditional checks use the when: syntax. When conditions can use raw Jinja2 expressions but can execute regular python code so can access methods like String.find() to check for a text match in a String. Multiple conditions should be enclosed with parenthesis, multiple conditions can be specified in a list where they are all required to be true (logical AND). Conditional check examples \u00b6 when : - tomcat_status_result.stdout.find(\"JVM is running.\") > -1 - tomcat_status_result.stderr != \"\" - tomcat_status_result.rc == 0 --- - hosts : all tasks : - name : \"print inventory vars\" debug : var : \"{{ item }}\" with_items : - inventory_dir - inventory_file when : inventory_dir | regex_search('dev$') - hosts : all tasks : - name : \"apply stub role\" include_role : name : issuer-wallet-stub when : inventory_dir | regex_search('dev$') Filters \u00b6 See documentation on filters . Filters use Jinja2, and Ansible ships with some extra ones to those available in Jinja2. Remember that if using a filter in a conditional statement that python methods are also accessible. Also note that the online Jinja2 documentation doesn't go back to python-jinja2 2.7 which is what is provided in RedHat repos for RHEL7. There are no RHEL plans to update Jinja2 to anything later, so what you read on the Jinja website will include features not available to Ansible on RHEL7, because of the Jinja2 version. To select an item from a list, based on an attribute, use the selectattr with the match filter, as the equalsto filter is only available in Jinja2 2.8. Given a yaml file like this, projects : - name : project-a version : '2.3.4-SNAPSHOT' - name : project-b version : '1.2.3-SNAPSHOT' - name : project-c value : '5.6.7-SNAPSHOT' Select the version of project-b using the following expression. - hosts : project-hosts-b vars : - deployable_version : \"{{ projects | selectattr('name', 'match', '^project-b$') | map(attribute='version') | list | first }}\" References jinja2-selectattr-filter Debug \u00b6 You can print a message with variable information in it, combine this with the verbosity level, below which the debug will not output anything. - debug : msg : \"System {{ inventory_hostname }} has gateway {{ ansible_default_ipv4.gateway }}\" verbosity : 4 when : ansible_default_ipv4.gateway is defined See documentation for the debug module . Play options \u00b6 Disable facts gathering - hosts : all gather_facts : false Import and Include \u00b6 Ansible documentation on Creating reusable playbooks Note there are trade-offs when selecting between static and dynamic, any import* tasks will be static, any include* tasks will be dynamic. All import* statements are pre-processed at the time playbooks are parsed. All include* statements are processed as they encountered during the execution of the playbook.","title":"Playbooks"},{"location":"ansible/playbooks/#playbooks","text":"","title":"Playbooks"},{"location":"ansible/playbooks/#conditional-checks","text":"Conditional checks use the when: syntax. When conditions can use raw Jinja2 expressions but can execute regular python code so can access methods like String.find() to check for a text match in a String. Multiple conditions should be enclosed with parenthesis, multiple conditions can be specified in a list where they are all required to be true (logical AND).","title":"Conditional checks"},{"location":"ansible/playbooks/#conditional-check-examples","text":"when : - tomcat_status_result.stdout.find(\"JVM is running.\") > -1 - tomcat_status_result.stderr != \"\" - tomcat_status_result.rc == 0 --- - hosts : all tasks : - name : \"print inventory vars\" debug : var : \"{{ item }}\" with_items : - inventory_dir - inventory_file when : inventory_dir | regex_search('dev$') - hosts : all tasks : - name : \"apply stub role\" include_role : name : issuer-wallet-stub when : inventory_dir | regex_search('dev$')","title":"Conditional check examples"},{"location":"ansible/playbooks/#filters","text":"See documentation on filters . Filters use Jinja2, and Ansible ships with some extra ones to those available in Jinja2. Remember that if using a filter in a conditional statement that python methods are also accessible. Also note that the online Jinja2 documentation doesn't go back to python-jinja2 2.7 which is what is provided in RedHat repos for RHEL7. There are no RHEL plans to update Jinja2 to anything later, so what you read on the Jinja website will include features not available to Ansible on RHEL7, because of the Jinja2 version. To select an item from a list, based on an attribute, use the selectattr with the match filter, as the equalsto filter is only available in Jinja2 2.8. Given a yaml file like this, projects : - name : project-a version : '2.3.4-SNAPSHOT' - name : project-b version : '1.2.3-SNAPSHOT' - name : project-c value : '5.6.7-SNAPSHOT' Select the version of project-b using the following expression. - hosts : project-hosts-b vars : - deployable_version : \"{{ projects | selectattr('name', 'match', '^project-b$') | map(attribute='version') | list | first }}\" References jinja2-selectattr-filter","title":"Filters"},{"location":"ansible/playbooks/#debug","text":"You can print a message with variable information in it, combine this with the verbosity level, below which the debug will not output anything. - debug : msg : \"System {{ inventory_hostname }} has gateway {{ ansible_default_ipv4.gateway }}\" verbosity : 4 when : ansible_default_ipv4.gateway is defined See documentation for the debug module .","title":"Debug"},{"location":"ansible/playbooks/#play-options","text":"Disable facts gathering - hosts : all gather_facts : false","title":"Play options"},{"location":"ansible/playbooks/#import-and-include","text":"Ansible documentation on Creating reusable playbooks Note there are trade-offs when selecting between static and dynamic, any import* tasks will be static, any include* tasks will be dynamic. All import* statements are pre-processed at the time playbooks are parsed. All include* statements are processed as they encountered during the execution of the playbook.","title":"Import and Include"},{"location":"ansible/tools/","text":"Ansible tools \u00b6 Ansible Run Analysis (ARA) \u00b6 See the ARA article or view the code on GitHub . Support \u00b6 Ansible Google Group Ansible Source and Releases on GitHub","title":"Ansible tools"},{"location":"ansible/tools/#ansible-tools","text":"","title":"Ansible tools"},{"location":"ansible/tools/#ansible-run-analysis-ara","text":"See the ARA article or view the code on GitHub .","title":"Ansible Run Analysis (ARA)"},{"location":"ansible/tools/#support","text":"Ansible Google Group Ansible Source and Releases on GitHub","title":"Support"},{"location":"ansible/tower/","text":"Ansible Tower \u00b6 AWX \u00b6 AWX is the upstream open-source version of Ansible Tower. See the AWX Project for details. You can get it from GitHub .","title":"Ansible Tower"},{"location":"ansible/tower/#ansible-tower","text":"","title":"Ansible Tower"},{"location":"ansible/tower/#awx","text":"AWX is the upstream open-source version of Ansible Tower. See the AWX Project for details. You can get it from GitHub .","title":"AWX"},{"location":"ansible/vars-and-facts/","text":"Vars and Facts \u00b6 Vars \u00b6 Magic variables \u00b6 The most commonly used magic variables are hostvars , groups , group_names , and inventory_hostname . groups is a list of all the groups (and hosts) in the inventory. Also available, inventory_dir is the pathname of the directory holding Ansible\u2019s inventory host file, inventory_file is the pathname and the filename pointing to the Ansible\u2019s inventory host file. See the ansible docs for more details. Group and Host Variables \u00b6 See documentation for playbooks best practices . inventory/group_vars/all.yaml my_var_name: \"some value\" Use {{ hostvars [ inventory_hostname ][ 'my_var_name' ] }} to reference. Note the group_vars/all structure does not mean there is an [all] hosts group to reference, but the vars in all will get applied to all group (hosts), and can be referenced using the magic variable inventory_hostname. Note the use of single quotes for the my_var_name (which is looking up the string 'my_var_name') vs the [inventory_hostname] syntax to index the inventory_hostname in the hostvars array. Load variables from a file \u00b6 On the command line, use -e or --extra-vars. Set additional variables as key=value or YAML/JSON, if filename prepend the filename with @. ansible-playbook ... --extra-vars '@my-vars.yaml' Combine vars from a file and additional vars by using --extra-vars twice. ansible-playbook ... --extra-vars '@my-vars.yaml' --extra-vars 'target_env=uat generate_report=true' See documentation Facts \u00b6 Setup module \u00b6 Basic example of running the setup module locally. ansible -m setup all -i localhost, --connection=local Sample Facts \u00b6 Quick reference for some of the facts I commonly use. Fact Values (not exhaustive list) ansible_os_family 'RedHat', 'Darwin', Debian' ansible_distribution 'CentOS', 'MacOSX', 'Ubuntu' ansible_distribution_major_version '7' ansible_distribution_version '7.4.1804' ansible_pkg_mgr 'yum', 'apt', 'homebrew' ansible_system 'Linux', 'Darwin' ansible_lsb dict containing id (ansible_distribution), release (ansible_distribution_version) and others. Depends on lsb package being installed. ansible_hostname ansible_fqdn ansible_env ansible_dns.nameservers List of name server IPs ansible_dns.search List of domains to search ansible_domain Access facts per host by just referencing the fact name as a variable. They are also available via {{ ansible_facts [ 'fact_name' ] }} or hostvars[inventory_hostname]['fact_name'] . Note that ansible_facts is a subset of hostvars[inventory_hostname]. --- - hosts : localhost connection : local tasks : - name : print ansible_facts debug : var : ansible_facts - name : print all host facts debug : var : hostvars[inventory_hostname]","title":"Vars and Facts"},{"location":"ansible/vars-and-facts/#vars-and-facts","text":"","title":"Vars and Facts"},{"location":"ansible/vars-and-facts/#vars","text":"","title":"Vars"},{"location":"ansible/vars-and-facts/#magic-variables","text":"The most commonly used magic variables are hostvars , groups , group_names , and inventory_hostname . groups is a list of all the groups (and hosts) in the inventory. Also available, inventory_dir is the pathname of the directory holding Ansible\u2019s inventory host file, inventory_file is the pathname and the filename pointing to the Ansible\u2019s inventory host file. See the ansible docs for more details.","title":"Magic variables"},{"location":"ansible/vars-and-facts/#group-and-host-variables","text":"See documentation for playbooks best practices . inventory/group_vars/all.yaml my_var_name: \"some value\" Use {{ hostvars [ inventory_hostname ][ 'my_var_name' ] }} to reference. Note the group_vars/all structure does not mean there is an [all] hosts group to reference, but the vars in all will get applied to all group (hosts), and can be referenced using the magic variable inventory_hostname. Note the use of single quotes for the my_var_name (which is looking up the string 'my_var_name') vs the [inventory_hostname] syntax to index the inventory_hostname in the hostvars array.","title":"Group and Host Variables"},{"location":"ansible/vars-and-facts/#load-variables-from-a-file","text":"On the command line, use -e or --extra-vars. Set additional variables as key=value or YAML/JSON, if filename prepend the filename with @. ansible-playbook ... --extra-vars '@my-vars.yaml' Combine vars from a file and additional vars by using --extra-vars twice. ansible-playbook ... --extra-vars '@my-vars.yaml' --extra-vars 'target_env=uat generate_report=true' See documentation","title":"Load variables from a file"},{"location":"ansible/vars-and-facts/#facts","text":"","title":"Facts"},{"location":"ansible/vars-and-facts/#setup-module","text":"Basic example of running the setup module locally. ansible -m setup all -i localhost, --connection=local","title":"Setup module"},{"location":"ansible/vars-and-facts/#sample-facts","text":"Quick reference for some of the facts I commonly use. Fact Values (not exhaustive list) ansible_os_family 'RedHat', 'Darwin', Debian' ansible_distribution 'CentOS', 'MacOSX', 'Ubuntu' ansible_distribution_major_version '7' ansible_distribution_version '7.4.1804' ansible_pkg_mgr 'yum', 'apt', 'homebrew' ansible_system 'Linux', 'Darwin' ansible_lsb dict containing id (ansible_distribution), release (ansible_distribution_version) and others. Depends on lsb package being installed. ansible_hostname ansible_fqdn ansible_env ansible_dns.nameservers List of name server IPs ansible_dns.search List of domains to search ansible_domain Access facts per host by just referencing the fact name as a variable. They are also available via {{ ansible_facts [ 'fact_name' ] }} or hostvars[inventory_hostname]['fact_name'] . Note that ansible_facts is a subset of hostvars[inventory_hostname]. --- - hosts : localhost connection : local tasks : - name : print ansible_facts debug : var : ansible_facts - name : print all host facts debug : var : hostvars[inventory_hostname]","title":"Sample Facts"},{"location":"bash/reference/","text":"Bash reference \u00b6 Process substitution \u00b6 This example was used to upload a file to post a file to a site requiriing authentication, without ever writing the credentials to disk or having them exposed in the command history or the running process list while the command is executing. Note that this code was run from a Jenkinsfile pipeline shared library, so the ${} variables are coming from Jenkins (Groovy) DSL. response_code = \\$ ( curl -w % { http_code } --netrc-file < ( cat <<< 'machine $uploadDomain login ${Username} password ${Password}' ) -sS --upload-file ${ filename } '${uploadUrl}' ) Breaking this command down <<<'Something here' is a here string , a variant of a here doc where the (variables in the) string are expanded before being fed to standard input. <( command ) is process substitution where the standard output of one process can be fed to the standard input of another process. In this case we're using process substitution and cat to feed curl with a netrc 'file' without ever writing the file to disk. --netrc-file is a curl option which can be used to provide credentials for curl to present when connecting to specified domains. Comments \u00b6 The # symbol is a bash comment, and can also be used to to stop processing of command line options. This is useful in git alias commands where we want to reference command line args in the git alias. Without the hash at the end of the alias below, using GitBash on Windows 10, the code will error with a message like grep : develop : No such file or directory . Adding the comment halts processing and the command works as expected. alias.prune-merged = !git branch --merged \" $1 \" | grep -v -e develop -e master -e \" $1 \" # Explain Shell \u00b6 Explain Shell can be useful to start to understand complex bash commands. Warning Remember this is a public (untrusted) website so be very careful about what you paste in here.","title":"Bash reference"},{"location":"bash/reference/#bash-reference","text":"","title":"Bash reference"},{"location":"bash/reference/#process-substitution","text":"This example was used to upload a file to post a file to a site requiriing authentication, without ever writing the credentials to disk or having them exposed in the command history or the running process list while the command is executing. Note that this code was run from a Jenkinsfile pipeline shared library, so the ${} variables are coming from Jenkins (Groovy) DSL. response_code = \\$ ( curl -w % { http_code } --netrc-file < ( cat <<< 'machine $uploadDomain login ${Username} password ${Password}' ) -sS --upload-file ${ filename } '${uploadUrl}' ) Breaking this command down <<<'Something here' is a here string , a variant of a here doc where the (variables in the) string are expanded before being fed to standard input. <( command ) is process substitution where the standard output of one process can be fed to the standard input of another process. In this case we're using process substitution and cat to feed curl with a netrc 'file' without ever writing the file to disk. --netrc-file is a curl option which can be used to provide credentials for curl to present when connecting to specified domains.","title":"Process substitution"},{"location":"bash/reference/#comments","text":"The # symbol is a bash comment, and can also be used to to stop processing of command line options. This is useful in git alias commands where we want to reference command line args in the git alias. Without the hash at the end of the alias below, using GitBash on Windows 10, the code will error with a message like grep : develop : No such file or directory . Adding the comment halts processing and the command works as expected. alias.prune-merged = !git branch --merged \" $1 \" | grep -v -e develop -e master -e \" $1 \" #","title":"Comments"},{"location":"bash/reference/#explain-shell","text":"Explain Shell can be useful to start to understand complex bash commands. Warning Remember this is a public (untrusted) website so be very careful about what you paste in here.","title":"Explain Shell"},{"location":"cheat-sheets/ansible/","text":"Ansible Cheat Sheet \u00b6 Debugging \u00b6 {{ inventory_hostname }} The inventory name for the current host being iterated over in the task. One of Ansible's Special Variables . {{ ansible_facts }} Dictionary of facts gathered or cached for the inventory_hostname . Print hostvars \u00b6 - name : print hostvars debug : var : hostvars[inventory_hostname] # This is the same as {{ ansible_facts }} but note that ansible_facts will work differntly to hostvars[inventory_hostname] when delegating actions to another host. verbosity : 2 Note that hostvars[inventory_hostname] will always give the facts for the specified inventory_hostname, whereas ansible_facts gives it for the machine the task is being run on. This behaviour will be apparent when delegating tasks to other machines, especially localhost which will not have had any facts gathered at all. Flow control \u00b6 Run a single task in serial in a Role. Note that the serial keyword is not applicable to a task, so we have to use a workaround with a side-effect which is that the host selected by Ansible to execute the run_once task will report as being changed even when the actual change took place on the host which the task was delegated to. - name : Enable and start the service service : name : my_service enabled : yes state : started delegate_to : \"{{ item }}\" run_once : true loop : \"{{ ansible_play_batch }}\" Loops \u00b6 Loops work with when and failed_when as well as the until conditions. when will be evaluated once prior to entering the loop, until will be evaluated as the loop repetition condition and finally the failed_when condition will be evaluated a single time only once the until condition is true or the loop has reached the maximum retry limit. - name : Poll for Cassandra connection shell : \"echo 'SHOW HOST;' | cqlsh {{ ansible_default_ipv4.address }} -u 'cassandra' --ssl\" register : result until : result.stderr.find(\"Connection refused\") == -1 retries : 10 delay : 10 changed_when : false failed_when : result.stderr.find(\"Connection refused\") != -1 Blocks \u00b6 Block sections include block , rescue and always . These function like try , catch and finally respectively. Blocks can accept options like run_once and tags, note that they can't be used to apply handlers which must be specified per task. Process files on host \u00b6 The find module can be used to find files on a remote host and then process them in later in the playbook by registering the output. The full filename and path is stored in the registered variable under files.path, which can be looped over as per the example below. - name : find all logstash plugins find : paths : \"{{ logstash_plugins_folder }}\" patterns : \"*.gem\" recurse : no register : plugin_gems changed_when : no - name : ensure all plugins are installed logstash_plugin : name : \"{{ item.path }}\" state : present loop : \"{{ plugin_gems.files }}\" notify : restart logstash Documentation \u00b6 Special Variables Keywords Filters Jinja2 Filters","title":"Ansible Cheat Sheet"},{"location":"cheat-sheets/ansible/#ansible-cheat-sheet","text":"","title":"Ansible Cheat Sheet"},{"location":"cheat-sheets/ansible/#debugging","text":"{{ inventory_hostname }} The inventory name for the current host being iterated over in the task. One of Ansible's Special Variables . {{ ansible_facts }} Dictionary of facts gathered or cached for the inventory_hostname .","title":"Debugging"},{"location":"cheat-sheets/ansible/#print-hostvars","text":"- name : print hostvars debug : var : hostvars[inventory_hostname] # This is the same as {{ ansible_facts }} but note that ansible_facts will work differntly to hostvars[inventory_hostname] when delegating actions to another host. verbosity : 2 Note that hostvars[inventory_hostname] will always give the facts for the specified inventory_hostname, whereas ansible_facts gives it for the machine the task is being run on. This behaviour will be apparent when delegating tasks to other machines, especially localhost which will not have had any facts gathered at all.","title":"Print hostvars"},{"location":"cheat-sheets/ansible/#flow-control","text":"Run a single task in serial in a Role. Note that the serial keyword is not applicable to a task, so we have to use a workaround with a side-effect which is that the host selected by Ansible to execute the run_once task will report as being changed even when the actual change took place on the host which the task was delegated to. - name : Enable and start the service service : name : my_service enabled : yes state : started delegate_to : \"{{ item }}\" run_once : true loop : \"{{ ansible_play_batch }}\"","title":"Flow control"},{"location":"cheat-sheets/ansible/#loops","text":"Loops work with when and failed_when as well as the until conditions. when will be evaluated once prior to entering the loop, until will be evaluated as the loop repetition condition and finally the failed_when condition will be evaluated a single time only once the until condition is true or the loop has reached the maximum retry limit. - name : Poll for Cassandra connection shell : \"echo 'SHOW HOST;' | cqlsh {{ ansible_default_ipv4.address }} -u 'cassandra' --ssl\" register : result until : result.stderr.find(\"Connection refused\") == -1 retries : 10 delay : 10 changed_when : false failed_when : result.stderr.find(\"Connection refused\") != -1","title":"Loops"},{"location":"cheat-sheets/ansible/#blocks","text":"Block sections include block , rescue and always . These function like try , catch and finally respectively. Blocks can accept options like run_once and tags, note that they can't be used to apply handlers which must be specified per task.","title":"Blocks"},{"location":"cheat-sheets/ansible/#process-files-on-host","text":"The find module can be used to find files on a remote host and then process them in later in the playbook by registering the output. The full filename and path is stored in the registered variable under files.path, which can be looped over as per the example below. - name : find all logstash plugins find : paths : \"{{ logstash_plugins_folder }}\" patterns : \"*.gem\" recurse : no register : plugin_gems changed_when : no - name : ensure all plugins are installed logstash_plugin : name : \"{{ item.path }}\" state : present loop : \"{{ plugin_gems.files }}\" notify : restart logstash","title":"Process files on host"},{"location":"cheat-sheets/ansible/#documentation","text":"Special Variables Keywords Filters Jinja2 Filters","title":"Documentation"},{"location":"cheat-sheets/jenkins/","text":"Jenkins \u00b6 As this is my cheat sheet I've used localhost:8080 in the markdown links for the Jenkins master. Replace localhost:8080 with the address of your Jenkins instance. Jenkinsfile Pipelines \u00b6 http://localhost:8080/pipeline-syntax/ - The Pipeline Syntax Snippet Generator, almost always generates valid Jenkins Pipeline DSL :) http://localhost:8080/pipeline-syntax/globals - Global 'variables' docs. In a shared or global library, add a .txt file alongside a .groovy file with text or HTML to automatically have add help to this globals page. http://localhost:8080/pipeline-syntax/gdsl - GDSL, auto-complete Jenkins DSL in IntelliJ JobDSL \u00b6 http://localhost:8080/plugin/job-dsl/api-viewer/index.html# - JobDSL API documentation, based on the installed plugins on the Jenkins master. JCasC \u00b6 http://localhost:8080/configuration-as-code/reference - Configration as code reference based on the installed (CasC) plugins and versions. Note not all of the available options are listed here, like the root jobs: option. http://localhost:8080/configuration-as-code/schema - JSON schema for the CasC options. Less descriptive and less readable but more complete than the above reference. External References \u00b6 https://javadoc.jenkins-ci.org/ - Java doc for Jenkins API","title":"Jenkins"},{"location":"cheat-sheets/jenkins/#jenkins","text":"As this is my cheat sheet I've used localhost:8080 in the markdown links for the Jenkins master. Replace localhost:8080 with the address of your Jenkins instance.","title":"Jenkins"},{"location":"cheat-sheets/jenkins/#jenkinsfile-pipelines","text":"http://localhost:8080/pipeline-syntax/ - The Pipeline Syntax Snippet Generator, almost always generates valid Jenkins Pipeline DSL :) http://localhost:8080/pipeline-syntax/globals - Global 'variables' docs. In a shared or global library, add a .txt file alongside a .groovy file with text or HTML to automatically have add help to this globals page. http://localhost:8080/pipeline-syntax/gdsl - GDSL, auto-complete Jenkins DSL in IntelliJ","title":"Jenkinsfile Pipelines"},{"location":"cheat-sheets/jenkins/#jobdsl","text":"http://localhost:8080/plugin/job-dsl/api-viewer/index.html# - JobDSL API documentation, based on the installed plugins on the Jenkins master.","title":"JobDSL"},{"location":"cheat-sheets/jenkins/#jcasc","text":"http://localhost:8080/configuration-as-code/reference - Configration as code reference based on the installed (CasC) plugins and versions. Note not all of the available options are listed here, like the root jobs: option. http://localhost:8080/configuration-as-code/schema - JSON schema for the CasC options. Less descriptive and less readable but more complete than the above reference.","title":"JCasC"},{"location":"cheat-sheets/jenkins/#external-references","text":"https://javadoc.jenkins-ci.org/ - Java doc for Jenkins API","title":"External References"},{"location":"cheat-sheets/markdown/","text":"Markdown \u00b6 Reference Links \u00b6 The implicit link name shorcut allows the 2 nd set of square brackets to be empty and the id should then be the same to the link name, ie the text in the first square brackets, although the ids are not case sensitive. [My Link text][ref_id] ... [ref_id]: https://mylink.com \"Optional link title\" References \u00b6","title":"Markdown"},{"location":"cheat-sheets/markdown/#markdown","text":"","title":"Markdown"},{"location":"cheat-sheets/markdown/#reference-links","text":"The implicit link name shorcut allows the 2 nd set of square brackets to be empty and the id should then be the same to the link name, ie the text in the first square brackets, although the ids are not case sensitive. [My Link text][ref_id] ... [ref_id]: https://mylink.com \"Optional link title\"","title":"Reference Links"},{"location":"cheat-sheets/markdown/#references","text":"","title":"References"},{"location":"cheat-sheets/vagrant/","text":"Vagrant \u00b6 Tips \u00b6 Ansible with Vagrant \u00b6 To reuse Vagrant VMs as the target for Ansible automation development, you can use a git submodule to include the repo with the Vagrantfile. In the Vagrantfile include an ansible provisioner then the provisioner will create an Ansible Inventory in .vagrant/provisioners/ansible/inventory which can then be used as the Ansible inventory from playbooks under development on the host, without having to copy/duplicate any files. Note that only the ansible provisioner creates this inventory, presumably because the provisioner itself is using this to provision the VMs from the host machine with Ansible. The ansible-local provisioner runs on the VMs so does not create an inventory on the Vagrant host. Multiple provisioners can be specified in the Vagrantfile, the inventory trick with the Ansible provisioner can co-exist alongside configuration with the ansible-local provisioner to further provision the VMs on startup should this be required. Ideally the base box would be built with Packer so that no time-consuming customisation is required when starting the VMs. Yes, Docker would be much faster, however there are times when a VM more closely replicates the target environment for the Ansible automation and this is desirable.","title":"Vagrant"},{"location":"cheat-sheets/vagrant/#vagrant","text":"","title":"Vagrant"},{"location":"cheat-sheets/vagrant/#tips","text":"","title":"Tips"},{"location":"cheat-sheets/vagrant/#ansible-with-vagrant","text":"To reuse Vagrant VMs as the target for Ansible automation development, you can use a git submodule to include the repo with the Vagrantfile. In the Vagrantfile include an ansible provisioner then the provisioner will create an Ansible Inventory in .vagrant/provisioners/ansible/inventory which can then be used as the Ansible inventory from playbooks under development on the host, without having to copy/duplicate any files. Note that only the ansible provisioner creates this inventory, presumably because the provisioner itself is using this to provision the VMs from the host machine with Ansible. The ansible-local provisioner runs on the VMs so does not create an inventory on the Vagrant host. Multiple provisioners can be specified in the Vagrantfile, the inventory trick with the Ansible provisioner can co-exist alongside configuration with the ansible-local provisioner to further provision the VMs on startup should this be required. Ideally the base box would be built with Packer so that no time-consuming customisation is required when starting the VMs. Yes, Docker would be much faster, however there are times when a VM more closely replicates the target environment for the Ansible automation and this is desirable.","title":"Ansible with Vagrant"},{"location":"jenkins/JenkinsPlugins/","text":"Jenkins Plugins \u00b6 Anyone who has ever administered Jenkins will know that plugins are both essential and problematic. Jenkins can be enhanced through an extensive collection of community maintained plugins, and therein lies the problem. \"Want to do 'A' with Jenkins? Yes you can. Want to do 'B' with Jenkins? Yes you can.\", goes the sales pitch. However, often A and B are implemented in community plugins which may conflict when installed 1 or may not work together even if both are installed. Custom tool plugin \u00b6 Not compatible with Pipelines until JENKINS-30680 is resolved. This has been open since September 2015. \"Installed\" must include restarting the Jenkins Master. I've had a plugin cause a conflict when installed, so I uninstalled it. The uninstall didn't resolve the conflict so I restarted to completely remove it. 12 hours later at 11:30pm I finally got the Jenkins Master up and running again. I'd been tracking down all the recent changes working backwards to find that a plugin installed 8 months previously (before I joined the company of course) was causing the conflict. I'd overlooked the signs initially, not believing that a change made 8 months ago could have caused the problem. The master had not been restarted in 8 months. If the master had been restarted at the time, the problem would have been detected immediately and the change rolled back right away. Lesson learned, always restart Jenkins after installing or removing plugins and check the logs to ensure the instance comes up cleanly. \u21a9","title":"Jenkins Plugins"},{"location":"jenkins/JenkinsPlugins/#jenkins-plugins","text":"Anyone who has ever administered Jenkins will know that plugins are both essential and problematic. Jenkins can be enhanced through an extensive collection of community maintained plugins, and therein lies the problem. \"Want to do 'A' with Jenkins? Yes you can. Want to do 'B' with Jenkins? Yes you can.\", goes the sales pitch. However, often A and B are implemented in community plugins which may conflict when installed 1 or may not work together even if both are installed.","title":"Jenkins Plugins"},{"location":"jenkins/JenkinsPlugins/#custom-tool-plugin","text":"Not compatible with Pipelines until JENKINS-30680 is resolved. This has been open since September 2015. \"Installed\" must include restarting the Jenkins Master. I've had a plugin cause a conflict when installed, so I uninstalled it. The uninstall didn't resolve the conflict so I restarted to completely remove it. 12 hours later at 11:30pm I finally got the Jenkins Master up and running again. I'd been tracking down all the recent changes working backwards to find that a plugin installed 8 months previously (before I joined the company of course) was causing the conflict. I'd overlooked the signs initially, not believing that a change made 8 months ago could have caused the problem. The master had not been restarted in 8 months. If the master had been restarted at the time, the problem would have been detected immediately and the change rolled back right away. Lesson learned, always restart Jenkins after installing or removing plugins and check the logs to ensure the instance comes up cleanly. \u21a9","title":"Custom tool plugin"},{"location":"jenkins/PipelineDSL/","text":"Pipeline DSL Notes \u00b6 Groovy closures \u00b6 There has been a long-standing bug with using closures like .each {} on collections, where the behaviour was incorrect and inconsistent. This gist demonstrates some of this behaviour. The bug has now been fixed in plugin:workflow-cps 2.33 although it's worth noting that there may still be other bugs like this which at the time of writing are still unresolved. Script approvals from libraries \u00b6 If you are a non-admin user writing Jenkins shared libraries, note that non-whitelisted methods will be blocked with an error indicating a script approval is required. Unfortunately library code does not raise a script approval for an admin to approve and the code in question has to be added to a Pipeline job where the methods are called directly from a Pipeline job using \"Pipeline script\" or \"Pipeline Script from SCM\". To address this, a pattern I have adopted is to include a Groovy Jenkinsfile in the shared library repository called script-approvals.groovy which makes all the method calls requiring approval. It is then easy to create a Jenkins job which executes this pipeline, which can be repeatedly executed by the team responsible for approving scripts until the script runs to completion. This is useful in environments where there are new or multiple Jenkins masters which a library will be used on.","title":"Pipeline DSL Notes"},{"location":"jenkins/PipelineDSL/#pipeline-dsl-notes","text":"","title":"Pipeline DSL Notes"},{"location":"jenkins/PipelineDSL/#groovy-closures","text":"There has been a long-standing bug with using closures like .each {} on collections, where the behaviour was incorrect and inconsistent. This gist demonstrates some of this behaviour. The bug has now been fixed in plugin:workflow-cps 2.33 although it's worth noting that there may still be other bugs like this which at the time of writing are still unresolved.","title":"Groovy closures"},{"location":"jenkins/PipelineDSL/#script-approvals-from-libraries","text":"If you are a non-admin user writing Jenkins shared libraries, note that non-whitelisted methods will be blocked with an error indicating a script approval is required. Unfortunately library code does not raise a script approval for an admin to approve and the code in question has to be added to a Pipeline job where the methods are called directly from a Pipeline job using \"Pipeline script\" or \"Pipeline Script from SCM\". To address this, a pattern I have adopted is to include a Groovy Jenkinsfile in the shared library repository called script-approvals.groovy which makes all the method calls requiring approval. It is then easy to create a Jenkins job which executes this pipeline, which can be repeatedly executed by the team responsible for approving scripts until the script runs to completion. This is useful in environments where there are new or multiple Jenkins masters which a library will be used on.","title":"Script approvals from libraries"},{"location":"jenkins/PipelineSteps/","text":"Pipeline Steps \u00b6 sh \u00b6 The bash defaults for running sh script is set -xe which will print all commands and arguments when executed (-x) and terminate on any non-zero exit code (-e). Note that this behaviour changes if using returnStatus : true . In this case the sh step will not terminate on error but the build will still be marked as failed overall, but the build execution will not be halted. It is down to you to check the value returned by the sh step. Quotes and sh \u00b6 Quotes in Jenkinsfiles are not always as simple to get right as you may think. Jenkinsfiles are groovy DSL, which often reference environment variables such as the values for parameterised jobs. Environment variables and groovy vars may both need to be passed to an echo step or to a sh step, sometimes to be evaluated in the Jenkins context, sometimes by the sh. An apparently simple task using process substitution to create a virtual .netrc file or creating a temporary json file (without using writeJSON ) is often not quite so straightforward unless you remember the rules for quotations for each context. Debugging sh scripts \u00b6 Add 'cat -n \\$0' into sh scripts to get Jenkins to echo out the shell script and line numbers into the console log, to check what Jenkins is actually executing on the agent. From this blog NonCPS annotation \u00b6 DSL code can only call methods or use classes which are serializable, unless the non-serializable methods are annotated with @NonCPS. Note there are additional considerations to be aware of. Methods annotated with @NonCPS cannot call any DSL methods, or any other methods unless the other methods are also annotated as NonCPS. Methods annotated with @NonCPS which call other methods will have undefined behaviour, including but not limited to returning unexpected values. Echo appears to be safe to use to log information from @NonCPS methods.","title":"Pipeline Steps"},{"location":"jenkins/PipelineSteps/#pipeline-steps","text":"","title":"Pipeline Steps"},{"location":"jenkins/PipelineSteps/#sh","text":"The bash defaults for running sh script is set -xe which will print all commands and arguments when executed (-x) and terminate on any non-zero exit code (-e). Note that this behaviour changes if using returnStatus : true . In this case the sh step will not terminate on error but the build will still be marked as failed overall, but the build execution will not be halted. It is down to you to check the value returned by the sh step.","title":"sh"},{"location":"jenkins/PipelineSteps/#quotes-and-sh","text":"Quotes in Jenkinsfiles are not always as simple to get right as you may think. Jenkinsfiles are groovy DSL, which often reference environment variables such as the values for parameterised jobs. Environment variables and groovy vars may both need to be passed to an echo step or to a sh step, sometimes to be evaluated in the Jenkins context, sometimes by the sh. An apparently simple task using process substitution to create a virtual .netrc file or creating a temporary json file (without using writeJSON ) is often not quite so straightforward unless you remember the rules for quotations for each context.","title":"Quotes and sh"},{"location":"jenkins/PipelineSteps/#debugging-sh-scripts","text":"Add 'cat -n \\$0' into sh scripts to get Jenkins to echo out the shell script and line numbers into the console log, to check what Jenkins is actually executing on the agent. From this blog","title":"Debugging sh scripts"},{"location":"jenkins/PipelineSteps/#noncps-annotation","text":"DSL code can only call methods or use classes which are serializable, unless the non-serializable methods are annotated with @NonCPS. Note there are additional considerations to be aware of. Methods annotated with @NonCPS cannot call any DSL methods, or any other methods unless the other methods are also annotated as NonCPS. Methods annotated with @NonCPS which call other methods will have undefined behaviour, including but not limited to returning unexpected values. Echo appears to be safe to use to log information from @NonCPS methods.","title":"NonCPS annotation"},{"location":"jenkins/administration/","text":"Jenkins Administration \u00b6 Security \u00b6 LTS does not mean patched \u00b6 Be aware that the Jenkins LTS release ships with default plugins which are not removable from the Jenkins instance and can be pinned to a low version, missing security updates. One such example is Jenkins LTS v2.176.2 which bundles the Ant plugin at version 1.2, released in 2013. There was a security advisory on 22 nd Jan 2018 which identified an XSS vulnerability in this plugin affecting versions up to and including 1.7 . At the time of writing this a year and a half later, the current LTS Jenkins is still bundling a version of this plugin from nearly 5 years prior. Many users will have no need for this plugin to be present, but it is not removable. I have to presume that the level of automated testing for Jenkins/CloudBees to perform even with less frequent LTS releases is prohibitive from patching all plugins even for security fixes.","title":"Jenkins Administration"},{"location":"jenkins/administration/#jenkins-administration","text":"","title":"Jenkins Administration"},{"location":"jenkins/administration/#security","text":"","title":"Security"},{"location":"jenkins/administration/#lts-does-not-mean-patched","text":"Be aware that the Jenkins LTS release ships with default plugins which are not removable from the Jenkins instance and can be pinned to a low version, missing security updates. One such example is Jenkins LTS v2.176.2 which bundles the Ant plugin at version 1.2, released in 2013. There was a security advisory on 22 nd Jan 2018 which identified an XSS vulnerability in this plugin affecting versions up to and including 1.7 . At the time of writing this a year and a half later, the current LTS Jenkins is still bundling a version of this plugin from nearly 5 years prior. Many users will have no need for this plugin to be present, but it is not removable. I have to presume that the level of automated testing for Jenkins/CloudBees to perform even with less frequent LTS releases is prohibitive from patching all plugins even for security fixes.","title":"LTS does not mean patched"},{"location":"linux/ius/","text":"IUS \u00b6 IUS is a project started by Rackspace to provide \"Inline with Upstream Stable\" package for RedHat/CentOS. Tools such as git are often outdated when installing via the standard RedHat base and epel repositories. IUS have a decent about page describing why the IUS project exists, read the link if you're interested. Consuming packages from IUS \u00b6 While there are setup and usage pages on the IUS website, there are still a couple of things to note when trying to find or install a package which are not well documented. Package names \u00b6 As per the safe replacement packages notes, IUS packages \"Uses a different name than the stock package to prevent unintended upgrades\". This means that with the ius release repo enabled you may need to search for a wildcard name, like yum list git* , in order to find the package name to install. The IUS package will not be called just git as this would clash with the stock package name from yum. There is a package search link on the IUS site. This navigates to GitHub where you can see some of the packages available. Searching here for git yielded the repo iusrepo/git222 . With the ius-release repo enabled, searching for packages matching git* also showed git2u which installs git v2.16.5-1.","title":"IUS"},{"location":"linux/ius/#ius","text":"IUS is a project started by Rackspace to provide \"Inline with Upstream Stable\" package for RedHat/CentOS. Tools such as git are often outdated when installing via the standard RedHat base and epel repositories. IUS have a decent about page describing why the IUS project exists, read the link if you're interested.","title":"IUS"},{"location":"linux/ius/#consuming-packages-from-ius","text":"While there are setup and usage pages on the IUS website, there are still a couple of things to note when trying to find or install a package which are not well documented.","title":"Consuming packages from IUS"},{"location":"linux/ius/#package-names","text":"As per the safe replacement packages notes, IUS packages \"Uses a different name than the stock package to prevent unintended upgrades\". This means that with the ius release repo enabled you may need to search for a wildcard name, like yum list git* , in order to find the package name to install. The IUS package will not be called just git as this would clash with the stock package name from yum. There is a package search link on the IUS site. This navigates to GitHub where you can see some of the packages available. Searching here for git yielded the repo iusrepo/git222 . With the ius-release repo enabled, searching for packages matching git* also showed git2u which installs git v2.16.5-1.","title":"Package names"},{"location":"python/mkdocs/","text":"MKDocs \u00b6 This site is built with MKDocs, hosted on GitHub Pages and automatically published on commit to master from Travis CI. Good documentation is vital for any enterprise IT team to publish shared practices or software components. To empower other teams and allow them to easily consume the output is key, in order to alleviate the publishing team from becoming yet-another-enterprise-bottleneck. MKDocs and GitHub Pages allows teams to publish documentation without having to worry about site hosting, and the documentation can be easily written in markdown. CI deployments to GitHub Pages with Travis-CI \u00b6 To publish from master onto the site served from the gh-pages branch I've used Travis CI for this open source site. I based my .travis.yml file on Derek Weitzel's blog post . As this was my first time using Travis I didn't initally understand what every line was for. A little piece of me dies whenever I see people cutting and pasting from the internet and executing code, or worse just \"curl bash piping\", especially in an enterprise organisation when they have no idea what code they are running. I've seen that happen way more times than I'd like. Anyway, here is my breakdown of the original script, followed by my enhancements. env : global : - GIT_NAME : \"'Markdown autodeploy'\" - GIT_EMAIL : djw8605 @ gmail . com - GH_REF : git @ github . com : opensciencegrid / security . git language : python Set some environment variables to use later in the job. Setting the language to python tells Travis CI to run this job on a docker container with python and pip pre-installed. before_script: - pip install mkdocs - pip install MarkdownHighlight This before_script phase will run prior to the (build) script section running. In the Job lifecycle Travis CI provides an install phase for installing dependencies which should be used instead. With this script there may be no practical difference between running these steps under the install or before_script phases, however I believe following the patterns intended by the tools is often an easier path to travel in the long term. script: - openssl aes-256-cbc -K $encrypted_1d262b48bc9b_key -iv $encrypted_1d262b48bc9b_iv -in deploy-key.enc -out deploy-key -d - chmod 600 deploy-key - eval `ssh-agent -s` - ssh-add deploy-key MKDocs needs to be able to commit and push to the gh-pages branch in the git repository. The openssl command decrypts the private ssh deploy key, then we limit the permissions and add the key to the running ssh agent. Restricting permissions is required otherwise ssh-add will refuse to add the overly permissive private key file. The eval statement is required to set the apropriate environment variables for the current shell instance so that you can connect to it with ssh-add. - git config user.name \"Automatic Publish\" - git config user.email \"djw8605@gmail.com\" - git remote add gh-token \" ${ GH_REF } \"; - git fetch gh-token && git fetch gh-token gh-pages:gh-pages; These steps are required in order for mkdocs to push to the GitHub gh-pages branch. In order to understand why, we need to look at the build log which shows Travis CI running something like the following $ git clone --depth = 50 --branch = master https://github.com/agarthetiger/mkdocs.git agarthetiger/mkdocs Cloning into 'agarthetiger/mkdocs' ... $ cd agarthetiger/mkdocs $ git checkout -qf cffa8d732d907f62a08262db229ee5899e2fc795 There would be two issues with trying to run mkdocs gh-deploy without the bulk of code in this script phase. First off, the --depth option on git clone implies --single-branch . If you add git branch -r or git remote show origin as steps into the script you can see that there is apparently no gh-pages branch in the remote. This behaviour can be changed by specifying git.depth: false in .travis.yml which will cause Travis CI to drop the --depth option and the clone will then fetch all branches. This can also be changed by telling git to clone all branches but there is still one more issue. The other issue is that we haven't provided a GitHub token or credentials to authenticate to the https GitHub remote with, so even if we add the branch to the origin we still can't push. The clone operation works as this is a public GitHub repository. Using a deploy key and ssh is preferable because any exposure of the credentials in this case would only compromise one repository via the deploy key, rather than compromising all repositories if using a GitHub token. Back to the original script, and adding a 2 nd remote allows the additional branches to be cloned over ssh and also to be pushed to using the decrypted key added to the ssh agent earlier for authentication. The fetch command can be simplified from the example because the initial git fetch gh-token fetches all branches. - if [ \" ${ TRAVIS_PULL_REQUEST } \" = \"false\" ]; then echo \"Pushing to github\"; PYTHONPATH=src/ mkdocs gh-deploy -v --clean --remote-name gh-token; git push gh-token gh-pages; fi; This line first checks to see whether the build was triggered from a Pull Request. Technically this could be avoided, because what we're doing here is building and deploying the website. We could build the site in the script phase of the .travis.yml file and then have all this ssh, git and deploy code running from the deploy phase. This is because the deploy phase is always skipped for Pull Requests . The script provider for deployments requires the script be defined in an external file, which is executed with bash. I've refactored this in my version, as the script example from the blog post is essentially individual bash commands in a yaml dictionary it was quick to translate into a file. Adding set -e to the file also allows the script to fail fast and terminate on the first non-zero exit code from a command. Failing fast on error is possibly but ugly to accomplish in the .travis.yml file, requiring every line to append || travis_terminate 1 and even this approach has problems . Travis CI Enhancements \u00b6 My yaml file looks like this. language : python branches : only : - master git : depth : 1 install : - pip install mkdocs - pip install mkdocs - material script : - if [[ $TRAVIS_PULL_REQUEST == \"false\" ]]; then mkdocs build -- strict ; fi ; deploy : skip_cleanup : true provider : script script : bash travis - ci / deploy - to - gh - pages . sh on : branch : master I kept the --depth option to still shallow clone the repo with a single branch for the build. Using the branches whitelist I could remove the requirement to check the branch name later in the script, and using a deploy phase meant no additional logic is required to check for pull requests or the branch in the shell script travis-ci/deploy-to-gh-pages.sh. deploy.skip_cleanup stops Travis from stashing changes in the workspace between the (build) script and deploy phases.","title":"MKDocs"},{"location":"python/mkdocs/#mkdocs","text":"This site is built with MKDocs, hosted on GitHub Pages and automatically published on commit to master from Travis CI. Good documentation is vital for any enterprise IT team to publish shared practices or software components. To empower other teams and allow them to easily consume the output is key, in order to alleviate the publishing team from becoming yet-another-enterprise-bottleneck. MKDocs and GitHub Pages allows teams to publish documentation without having to worry about site hosting, and the documentation can be easily written in markdown.","title":"MKDocs"},{"location":"python/mkdocs/#ci-deployments-to-github-pages-with-travis-ci","text":"To publish from master onto the site served from the gh-pages branch I've used Travis CI for this open source site. I based my .travis.yml file on Derek Weitzel's blog post . As this was my first time using Travis I didn't initally understand what every line was for. A little piece of me dies whenever I see people cutting and pasting from the internet and executing code, or worse just \"curl bash piping\", especially in an enterprise organisation when they have no idea what code they are running. I've seen that happen way more times than I'd like. Anyway, here is my breakdown of the original script, followed by my enhancements. env : global : - GIT_NAME : \"'Markdown autodeploy'\" - GIT_EMAIL : djw8605 @ gmail . com - GH_REF : git @ github . com : opensciencegrid / security . git language : python Set some environment variables to use later in the job. Setting the language to python tells Travis CI to run this job on a docker container with python and pip pre-installed. before_script: - pip install mkdocs - pip install MarkdownHighlight This before_script phase will run prior to the (build) script section running. In the Job lifecycle Travis CI provides an install phase for installing dependencies which should be used instead. With this script there may be no practical difference between running these steps under the install or before_script phases, however I believe following the patterns intended by the tools is often an easier path to travel in the long term. script: - openssl aes-256-cbc -K $encrypted_1d262b48bc9b_key -iv $encrypted_1d262b48bc9b_iv -in deploy-key.enc -out deploy-key -d - chmod 600 deploy-key - eval `ssh-agent -s` - ssh-add deploy-key MKDocs needs to be able to commit and push to the gh-pages branch in the git repository. The openssl command decrypts the private ssh deploy key, then we limit the permissions and add the key to the running ssh agent. Restricting permissions is required otherwise ssh-add will refuse to add the overly permissive private key file. The eval statement is required to set the apropriate environment variables for the current shell instance so that you can connect to it with ssh-add. - git config user.name \"Automatic Publish\" - git config user.email \"djw8605@gmail.com\" - git remote add gh-token \" ${ GH_REF } \"; - git fetch gh-token && git fetch gh-token gh-pages:gh-pages; These steps are required in order for mkdocs to push to the GitHub gh-pages branch. In order to understand why, we need to look at the build log which shows Travis CI running something like the following $ git clone --depth = 50 --branch = master https://github.com/agarthetiger/mkdocs.git agarthetiger/mkdocs Cloning into 'agarthetiger/mkdocs' ... $ cd agarthetiger/mkdocs $ git checkout -qf cffa8d732d907f62a08262db229ee5899e2fc795 There would be two issues with trying to run mkdocs gh-deploy without the bulk of code in this script phase. First off, the --depth option on git clone implies --single-branch . If you add git branch -r or git remote show origin as steps into the script you can see that there is apparently no gh-pages branch in the remote. This behaviour can be changed by specifying git.depth: false in .travis.yml which will cause Travis CI to drop the --depth option and the clone will then fetch all branches. This can also be changed by telling git to clone all branches but there is still one more issue. The other issue is that we haven't provided a GitHub token or credentials to authenticate to the https GitHub remote with, so even if we add the branch to the origin we still can't push. The clone operation works as this is a public GitHub repository. Using a deploy key and ssh is preferable because any exposure of the credentials in this case would only compromise one repository via the deploy key, rather than compromising all repositories if using a GitHub token. Back to the original script, and adding a 2 nd remote allows the additional branches to be cloned over ssh and also to be pushed to using the decrypted key added to the ssh agent earlier for authentication. The fetch command can be simplified from the example because the initial git fetch gh-token fetches all branches. - if [ \" ${ TRAVIS_PULL_REQUEST } \" = \"false\" ]; then echo \"Pushing to github\"; PYTHONPATH=src/ mkdocs gh-deploy -v --clean --remote-name gh-token; git push gh-token gh-pages; fi; This line first checks to see whether the build was triggered from a Pull Request. Technically this could be avoided, because what we're doing here is building and deploying the website. We could build the site in the script phase of the .travis.yml file and then have all this ssh, git and deploy code running from the deploy phase. This is because the deploy phase is always skipped for Pull Requests . The script provider for deployments requires the script be defined in an external file, which is executed with bash. I've refactored this in my version, as the script example from the blog post is essentially individual bash commands in a yaml dictionary it was quick to translate into a file. Adding set -e to the file also allows the script to fail fast and terminate on the first non-zero exit code from a command. Failing fast on error is possibly but ugly to accomplish in the .travis.yml file, requiring every line to append || travis_terminate 1 and even this approach has problems .","title":"CI deployments to GitHub Pages with Travis-CI"},{"location":"python/mkdocs/#travis-ci-enhancements","text":"My yaml file looks like this. language : python branches : only : - master git : depth : 1 install : - pip install mkdocs - pip install mkdocs - material script : - if [[ $TRAVIS_PULL_REQUEST == \"false\" ]]; then mkdocs build -- strict ; fi ; deploy : skip_cleanup : true provider : script script : bash travis - ci / deploy - to - gh - pages . sh on : branch : master I kept the --depth option to still shallow clone the repo with a single branch for the build. Using the branches whitelist I could remove the requirement to check the branch name later in the script, and using a deploy phase meant no additional logic is required to check for pull requests or the branch in the shell script travis-ci/deploy-to-gh-pages.sh. deploy.skip_cleanup stops Travis from stashing changes in the workspace between the (build) script and deploy phases.","title":"Travis CI Enhancements"},{"location":"python/resources/","text":"Python Resources \u00b6 Using Python with Docker - pythonspeed.com","title":"Python Resources"},{"location":"python/resources/#python-resources","text":"Using Python with Docker - pythonspeed.com","title":"Python Resources"},{"location":"terraform/resources/","text":"Terraform resources \u00b6 InfoQ - Automated infrastructure testing Terragrunt - Keeing IaC DRY","title":"Terraform resources"},{"location":"terraform/resources/#terraform-resources","text":"InfoQ - Automated infrastructure testing Terragrunt - Keeing IaC DRY","title":"Terraform resources"}]}